---
title: "Image Segmentation Using Transformers"
excerpt: "Conducted a comparative study on transformer-based (ViT, UNet Transformer) and CNN (SegNet) models for image segmentation, leveraging the OxfordIIIT pet dataset to analyze efficacy across architectural configurations."
collection: portfolio
---
Abstract
------
 Image segmentation, a pivotal task in computer vision, facilitates the precise delineation and classification of objects or regions within images. In this comparative study, we investigate the efficacy of transformer-based models such as ViT (Vision Transformer) and UNet Transformer, alongside the CNN model SegNet, across various architectural configurations for image segmentation tasks. Leveraging the OxfordIIIT pet dataset, we meticulously train and evaluate these models, presenting detailed analyses and performance comparisons. These comparisons clearly indicate the promising nature of Ensembling UNet (with ResNet50, DenseNet121 and MobileNet v2) while ViT based models perform spectacularly poor all accross given the high number of parameters. You can read further about the study over [here](https://github.com/eshaanraj25/Deep-Dive-into-Transformer-Segmentation-A-Comparative-Architectural-Study)
